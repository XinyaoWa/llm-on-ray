name: Finetune on Intel GPU

on:
  workflow_call:

env:
  ACTIONS_RUNNER_CONTAINER_IMAGE: 10.1.2.13:5000/llmray-build
  HTTPS_PROXY_CONTAINER: http://proxy-chain.intel.com:911
  HTTP_PROXY_CONTAINER: http://proxy-chain.intel.com:911

jobs:
  finetune:
    name: finetune on gpu test
    strategy:
      matrix:
        model: [ pythia-6.9b, gpt-j-6b ]
    runs-on: self-hosted

    defaults:
      run:
        shell: bash
    container:
      image: "$ACTIONS_RUNNER_CONTAINER_IMAGE"
      env:
        http_proxy: "$HTTP_PROXY_CONTAINER"
        https_proxy: "$HTTPS_PROXY_CONTAINER"
      volumes:
        - /var/run/docker.sock:/var/run/docker.sock

    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Running task on Intel GPU
        run: |
          rm ~/borealis-runner/llm-on-ray.tar.gz -f
          tar zcf ~/borealis-runner/llm-on-ray.tar.gz -C ~/actions-runner/_work/llm-on-ray .
          cd ~/borealis-runner/
          python3 finetune_on_pvc.py --base_model "${{ matrix.model }}"
      - name: Test Summary
        run: echo "to be continued"