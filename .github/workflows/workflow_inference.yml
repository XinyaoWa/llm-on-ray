name: Inference

on:
  workflow_call:
    inputs:
      ci_type:
        type: string
        default: 'pr'

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}-inf
  cancel-in-progress: true

jobs:
  inference:
    name: inference test
    strategy:
      matrix:
        # for mistral-7b-v0.1, we use bigdl-cpu to verify
        model: [ gpt-j-6b, gpt2, bloom-560m, opt-125m, mpt-7b, mistral-7b-v0.1, mpt-7b-bigdl ]
        isPR:
          - ${{inputs.ci_type == 'pr'}}

        exclude:
          - { isPR: true }

        include:
          - { model: "gpt-j-6b"}
          - { model: "mistral-7b-v0.1"}
          - { model: "mpt-7b-bigdl"}
          - dtuner_model: nathan0/mpt-7b-deltatuner-model
            model: mpt-7b

    runs-on: self-hosted
    container:
      image: 10.1.2.13:5000/llmray-build
      volumes:
        - /var/run/docker.sock:/var/run/docker.sock
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Show env
        run: |
          (ls /.dockerenv && echo Found dockerenv) || (echo No dockerenv)
          echo "code dir is $GITHUB_WORKSPACE"
          docker image ls


      