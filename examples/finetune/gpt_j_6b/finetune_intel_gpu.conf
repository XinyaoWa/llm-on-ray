{
    "General": {
        "base_model": "EleutherAI/gpt-j-6b",
        # fix issue: https://github.com/huggingface/transformers/issues/22482
        # tranformers version 4.26.0 is required for gpt2, gpt-j-6B, pythia...
        "gpt_base_model": True,
        "output_dir": "/tmp/llm-ray/output",
        "checkpoint_dir": "/tmp/llm-ray/checkpoint",
        "config": {
            "trust_remote_code": False,
            "use_auth_token": None,
        },
        "lora_config": {
            "task_type": "CAUSAL_LM",
            "r": 8,
            "lora_alpha": 32,
            "lora_dropout": 0.1
        }
    },
    "Dataset": {
        "train_file": "examples/data/sample_finetune_data.jsonl",
        "validation_file": None,
        "validation_split_percentage": 5
    },
    "Training": {
        "optimizer": "AdamW",
        "batch_size": 4,
        "epochs": 3,
        "learning_rate": 1e-5,
        "lr_scheduler": "linear",
        "weight_decay": 0.0,
        "device": "GPU",
        "num_training_workers": 2,
        "accelerate_mode": "GPU_DDP",
        "resources_per_worker": {
            "CPU": 1,
            "GPU": 1,
        },
    },
}

